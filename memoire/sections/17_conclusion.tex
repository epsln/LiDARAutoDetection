The aim of this project was to develop an object detection architecture more suited for use with remote sensing data, and inscribe itself in a growing body of research in this area. While Deep Learning is still a relatively novel technique, this work further establishes it as a robust, efficient and high performance method for detection. 

This project, while being in essence a \textit{research subject} and not a \textit{engineering subject} has allowed me to put into a application a wide range of state of the art techniques, and to have entire control over. 

Indeed, what is usually the case in Deep Learning projects is that a dataset is used \textit{as is} and never modified. One will then create an architecture, train it, and evaluate. More often than not, the architecture of the model is also used as is. In this project, I was provided with a dataset, but I was able to modify it. I was able to chose which Deep Learning framework to use, what type of architecture, what kind of modifications to apply, what kind of training regime to use and so on. This liberty allowed me to tweak the model and its training, and make it more suitable for the task. I applied what I learned at my last internship at SNCF, where I was also tasked with the development of a ML project from end to end. 

From an engineering standpoint, and more precisely a project management point of view, those two experiences gave me insight into how a Deep Learning project can be conducted and what are the differences and parallels with more traditional Software Engineering tasks. 

A Deep Learning project should start with a thorough review of the state of the art in the field. While this isn't too dissimilar with a review of the technologies that could be used in a Software Engineering project, the main difference is the review will usually be done with recent research papers, and techniques that are young and not necessarily proven. This also means that a high level of familiarity with recent trends in Deep Learning research is required, and that a lot of testing is needed to separates good ideas and techniques from the inefficient and/or ineffective.

 Deep Learning moves very fast and new, potentially ground breaking papers are published almost everyday. For example, the paper detailing YOLOv4, the center piece of this project was published at the end of April 2020, right at the end of the allotted time I had to write a State of the Art document. This means that the monitoring of the recent advances needs to be done much more closely. This in turn poses an interesting problem: in a more traditional Software Engineering environment, that simply make use of those models, how can we follow the break neck speed of development of Deep Learning and apply them ? The Technical Debt accrued by those methods grow much faster: and a model using techniques even a few years old can be entirely outdated. The challenges is to embed those models and techniques into a more traditional software engineering environment while being able to modify them regularly. 


